{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245d3aef",
   "metadata": {},
   "source": [
    "# Î²-VAE\n",
    "\n",
    "https://github.com/1Konny/Beta-VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c55aa",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238a28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.py\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def reparametrize(mu, logvar):\n",
    "    std = logvar.div(2).exp()\n",
    "    eps = Variable(std.data.new(std.size()).normal_())\n",
    "    return mu + std*eps\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "\n",
    "class BetaVAE_H(nn.Module):\n",
    "    \"\"\"Model proposed in original beta-VAE paper(Higgins et al, ICLR, 2017).\"\"\"\n",
    "\n",
    "    def __init__(self, z_dim=10, nc=3):\n",
    "        super(BetaVAE_H, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.nc = nc\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(nc, 32, 4, 2, 1),          # B,  32, 32, 32\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32, 16, 16\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),          # B,  64,  8,  8\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 4, 2, 1),          # B,  64,  4,  4\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 256, 4, 1),            # B, 256,  1,  1\n",
    "            nn.ReLU(True),\n",
    "            View((-1, 256*1*1)),                 # B, 256\n",
    "            nn.Linear(256, z_dim*2),             # B, z_dim*2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),               # B, 256\n",
    "            View((-1, 256, 1, 1)),               # B, 256,  1,  1\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 64, 4),      # B,  64,  4,  4\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 64, 4, 2, 1), # B,  64,  8,  8\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), # B,  32, 16, 16\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 32, 32\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, nc, 4, 2, 1),  # B, nc, 64, 64\n",
    "        )\n",
    "\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distributions = self._encode(x)\n",
    "        mu = distributions[:, :self.z_dim]\n",
    "        logvar = distributions[:, self.z_dim:]\n",
    "        z = reparametrize(mu, logvar)\n",
    "        x_recon = self._decode(z)\n",
    "\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    def _encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def _decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "class BetaVAE_B(BetaVAE_H):\n",
    "    \"\"\"Model proposed in understanding beta-VAE paper(Burgess et al, arxiv:1804.03599, 2018).\"\"\"\n",
    "\n",
    "    def __init__(self, z_dim=10, nc=1):\n",
    "        super(BetaVAE_B, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(nc, 32, 4, 2, 1),          # B,  32, 32, 32\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32, 16, 16\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32,  8,  8\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32,  4,  4\n",
    "            nn.ReLU(True),\n",
    "            View((-1, 32*4*4)),                  # B, 512\n",
    "            nn.Linear(32*4*4, 256),              # B, 256\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 256),                 # B, 256\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, z_dim*2),             # B, z_dim*2\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),               # B, 256\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 256),                 # B, 256\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 32*4*4),              # B, 512\n",
    "            nn.ReLU(True),\n",
    "            View((-1, 32, 4, 4)),                # B,  32,  4,  4\n",
    "            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32,  8,  8\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 16, 16\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 32, 32\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, nc, 4, 2, 1), # B,  nc, 64, 64\n",
    "        )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        distributions = self._encode(x)\n",
    "        mu = distributions[:, :self.z_dim]\n",
    "        logvar = distributions[:, self.z_dim:]\n",
    "        z = reparametrize(mu, logvar)\n",
    "        x_recon = self._decode(z).view(x.size())\n",
    "\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    def _encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def _decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "def kaiming_init(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        init.kaiming_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        if m.bias.data is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias.data is not None:\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825b577",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc2ad9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"utils.py\"\"\"\n",
    "\n",
    "import argparse\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def cuda(tensor, uses_cuda):\n",
    "    return tensor.cuda() if uses_cuda else tensor\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    # codes from : https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparse\n",
    "\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def where(cond, x, y):\n",
    "    \"\"\"Do same operation as np.where\n",
    "\n",
    "    code from:\n",
    "        https://discuss.pytorch.org/t/how-can-i-do-the-operation-the-same-as-np-where/1329/8\n",
    "    \"\"\"\n",
    "    cond = cond.float()\n",
    "    return (cond*x) + ((1-cond)*y)\n",
    "\n",
    "\n",
    "def grid2gif(image_str, output_gif, delay=100):\n",
    "    \"\"\"Make GIF from images.\n",
    "\n",
    "    code from:\n",
    "        https://stackoverflow.com/questions/753190/programmatically-generate-video-or-animated-gif-in-python/34555939#34555939\n",
    "    \"\"\"\n",
    "    str1 = 'convert -delay '+str(delay)+' -loop 0 ' + image_str  + ' ' + output_gif\n",
    "    subprocess.call(str1, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb83b50",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4098481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dataset.py\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def is_power_of_2(num):\n",
    "    return ((num & (num - 1)) == 0) and num != 0\n",
    "\n",
    "\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(CustomImageFolder, self).__init__(root, transform)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.imgs[index][0]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "\n",
    "\n",
    "def return_data(args):\n",
    "    name = args.dataset\n",
    "    dset_dir = args.dset_dir\n",
    "    batch_size = args.batch_size\n",
    "    num_workers = args.num_workers\n",
    "    image_size = args.image_size\n",
    "    assert image_size == 64, 'currently only image size of 64 is supported'\n",
    "\n",
    "    if name.lower() == '3dchairs':\n",
    "        root = os.path.join(dset_dir, '3DChairs')\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),])\n",
    "        train_kwargs = {'root':root, 'transform':transform}\n",
    "        dset = CustomImageFolder\n",
    "\n",
    "    elif name.lower() == 'celeba':\n",
    "        root = os.path.join(dset_dir, 'CelebA')\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),])\n",
    "        train_kwargs = {'root':root, 'transform':transform}\n",
    "        dset = CustomImageFolder\n",
    "\n",
    "    elif name.lower() == 'dsprites':\n",
    "        root = os.path.join(dset_dir, 'dsprites-dataset/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz')\n",
    "        if not os.path.exists(root):\n",
    "            import subprocess\n",
    "            print('Now download dsprites-dataset')\n",
    "            subprocess.call(['./download_dsprites.sh'])\n",
    "            print('Finished')\n",
    "        data = np.load(root, encoding='bytes')\n",
    "        data = torch.from_numpy(data['imgs']).unsqueeze(1).float()\n",
    "        train_kwargs = {'data_tensor':data}\n",
    "        dset = CustomTensorDataset\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    train_data = dset(**train_kwargs)\n",
    "    train_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    data_loader = train_loader\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fdc4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"solver.py\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import visdom\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "#from utils import cuda, grid2gif\n",
    "#from model import BetaVAE_H, BetaVAE_B\n",
    "#from dataset import return_data\n",
    "\n",
    "\n",
    "def reconstruction_loss(x, x_recon, distribution):\n",
    "    batch_size = x.size(0)\n",
    "    assert batch_size != 0\n",
    "\n",
    "    if distribution == 'bernoulli':\n",
    "        recon_loss = F.binary_cross_entropy_with_logits(x_recon, x, size_average=False).div(batch_size)\n",
    "    elif distribution == 'gaussian':\n",
    "        x_recon = F.sigmoid(x_recon)\n",
    "        recon_loss = F.mse_loss(x_recon, x, size_average=False).div(batch_size)\n",
    "    else:\n",
    "        recon_loss = None\n",
    "\n",
    "    return recon_loss\n",
    "\n",
    "\n",
    "def kl_divergence(mu, logvar):\n",
    "    batch_size = mu.size(0)\n",
    "    assert batch_size != 0\n",
    "    if mu.data.ndimension() == 4:\n",
    "        mu = mu.view(mu.size(0), mu.size(1))\n",
    "    if logvar.data.ndimension() == 4:\n",
    "        logvar = logvar.view(logvar.size(0), logvar.size(1))\n",
    "\n",
    "    klds = -0.5*(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    total_kld = klds.sum(1).mean(0, True)\n",
    "    dimension_wise_kld = klds.mean(0)\n",
    "    mean_kld = klds.mean(1).mean(0, True)\n",
    "\n",
    "    return total_kld, dimension_wise_kld, mean_kld\n",
    "\n",
    "\n",
    "class DataGather(object):\n",
    "    def __init__(self):\n",
    "        self.data = self.get_empty_data_dict()\n",
    "\n",
    "    def get_empty_data_dict(self):\n",
    "        return dict(iter=[],\n",
    "                    recon_loss=[],\n",
    "                    total_kld=[],\n",
    "                    dim_wise_kld=[],\n",
    "                    mean_kld=[],\n",
    "                    mu=[],\n",
    "                    var=[],\n",
    "                    images=[],)\n",
    "\n",
    "    def insert(self, **kwargs):\n",
    "        for key in kwargs:\n",
    "            self.data[key].append(kwargs[key])\n",
    "\n",
    "    def flush(self):\n",
    "        self.data = self.get_empty_data_dict()\n",
    "\n",
    "\n",
    "class Solver(object):\n",
    "    def __init__(self, args):\n",
    "        self.use_cuda = args.cuda and torch.cuda.is_available()\n",
    "        self.max_iter = args.max_iter\n",
    "        self.global_iter = 0\n",
    "\n",
    "        self.z_dim = args.z_dim\n",
    "        self.beta = args.beta\n",
    "        self.gamma = args.gamma\n",
    "        self.C_max = args.C_max\n",
    "        self.C_stop_iter = args.C_stop_iter\n",
    "        self.objective = args.objective\n",
    "        self.model = args.model\n",
    "        self.lr = args.lr\n",
    "        self.beta1 = args.beta1\n",
    "        self.beta2 = args.beta2\n",
    "\n",
    "        if args.dataset.lower() == 'dsprites':\n",
    "            self.nc = 1\n",
    "            self.decoder_dist = 'bernoulli'\n",
    "        elif args.dataset.lower() == '3dchairs':\n",
    "            self.nc = 3\n",
    "            self.decoder_dist = 'gaussian'\n",
    "        elif args.dataset.lower() == 'celeba':\n",
    "            self.nc = 3\n",
    "            self.decoder_dist = 'gaussian'\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if args.model == 'H':\n",
    "            net = BetaVAE_H\n",
    "        elif args.model == 'B':\n",
    "            net = BetaVAE_B\n",
    "        else:\n",
    "            raise NotImplementedError('only support model H or B')\n",
    "\n",
    "        self.net = cuda(net(self.z_dim, self.nc), self.use_cuda)\n",
    "        self.optim = optim.Adam(self.net.parameters(), lr=self.lr,\n",
    "                                    betas=(self.beta1, self.beta2))\n",
    "\n",
    "        self.viz_name = args.viz_name\n",
    "        self.viz_port = args.viz_port\n",
    "        self.viz_on = args.viz_on\n",
    "        self.win_recon = None\n",
    "        self.win_kld = None\n",
    "        self.win_mu = None\n",
    "        self.win_var = None\n",
    "        if self.viz_on:\n",
    "            self.viz = visdom.Visdom(port=self.viz_port)\n",
    "\n",
    "        self.ckpt_dir = os.path.join(args.ckpt_dir, args.viz_name)\n",
    "        if not os.path.exists(self.ckpt_dir):\n",
    "            os.makedirs(self.ckpt_dir, exist_ok=True)\n",
    "        self.ckpt_name = args.ckpt_name\n",
    "        if self.ckpt_name is not None:\n",
    "            self.load_checkpoint(self.ckpt_name)\n",
    "\n",
    "        self.save_output = args.save_output\n",
    "        self.output_dir = os.path.join(args.output_dir, args.viz_name)\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        self.gather_step = args.gather_step\n",
    "        self.display_step = args.display_step\n",
    "        self.save_step = args.save_step\n",
    "\n",
    "        self.dset_dir = args.dset_dir\n",
    "        self.dataset = args.dataset\n",
    "        self.batch_size = args.batch_size\n",
    "        self.data_loader = return_data(args)\n",
    "\n",
    "        self.gather = DataGather()\n",
    "\n",
    "    def train(self):\n",
    "        self.net_mode(train=True)\n",
    "        self.C_max = Variable(cuda(torch.FloatTensor([self.C_max]), self.use_cuda))\n",
    "        out = False\n",
    "\n",
    "        pbar = tqdm(total=self.max_iter)\n",
    "        pbar.update(self.global_iter)\n",
    "        while not out:\n",
    "            for x in self.data_loader:\n",
    "                self.global_iter += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "                x = Variable(cuda(x, self.use_cuda))\n",
    "                x_recon, mu, logvar = self.net(x)\n",
    "                recon_loss = reconstruction_loss(x, x_recon, self.decoder_dist)\n",
    "                total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)\n",
    "\n",
    "                if self.objective == 'H':\n",
    "                    beta_vae_loss = recon_loss + self.beta*total_kld\n",
    "                elif self.objective == 'B':\n",
    "                    C = torch.clamp(self.C_max/self.C_stop_iter*self.global_iter, 0, self.C_max.data[0])\n",
    "                    beta_vae_loss = recon_loss + self.gamma*(total_kld-C).abs()\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "                beta_vae_loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                if self.viz_on and self.global_iter%self.gather_step == 0:\n",
    "                    self.gather.insert(iter=self.global_iter,\n",
    "                                       mu=mu.mean(0).data, var=logvar.exp().mean(0).data,\n",
    "                                       recon_loss=recon_loss.data, total_kld=total_kld.data,\n",
    "                                       dim_wise_kld=dim_wise_kld.data, mean_kld=mean_kld.data)\n",
    "\n",
    "                if self.global_iter%self.display_step == 0:\n",
    "                    pbar.write('[{}] recon_loss:{:.3f} total_kld:{:.3f} mean_kld:{:.3f}'.format(\n",
    "                        self.global_iter, recon_loss.data[0], total_kld.data[0], mean_kld.data[0]))\n",
    "\n",
    "                    var = logvar.exp().mean(0).data\n",
    "                    var_str = ''\n",
    "                    for j, var_j in enumerate(var):\n",
    "                        var_str += 'var{}:{:.4f} '.format(j+1, var_j)\n",
    "                    pbar.write(var_str)\n",
    "\n",
    "                    if self.objective == 'B':\n",
    "                        pbar.write('C:{:.3f}'.format(C.data[0]))\n",
    "\n",
    "                    if self.viz_on:\n",
    "                        self.gather.insert(images=x.data)\n",
    "                        self.gather.insert(images=F.sigmoid(x_recon).data)\n",
    "                        self.viz_reconstruction()\n",
    "                        self.viz_lines()\n",
    "                        self.gather.flush()\n",
    "\n",
    "                    if self.viz_on or self.save_output:\n",
    "                        self.viz_traverse()\n",
    "\n",
    "                if self.global_iter%self.save_step == 0:\n",
    "                    self.save_checkpoint('last')\n",
    "                    pbar.write('Saved checkpoint(iter:{})'.format(self.global_iter))\n",
    "\n",
    "                if self.global_iter%50000 == 0:\n",
    "                    self.save_checkpoint(str(self.global_iter))\n",
    "\n",
    "                if self.global_iter >= self.max_iter:\n",
    "                    out = True\n",
    "                    break\n",
    "\n",
    "        pbar.write(\"[Training Finished]\")\n",
    "        pbar.close()\n",
    "\n",
    "    def viz_reconstruction(self):\n",
    "        self.net_mode(train=False)\n",
    "        x = self.gather.data['images'][0][:100]\n",
    "        x = make_grid(x, normalize=True)\n",
    "        x_recon = self.gather.data['images'][1][:100]\n",
    "        x_recon = make_grid(x_recon, normalize=True)\n",
    "        images = torch.stack([x, x_recon], dim=0).cpu()\n",
    "        self.viz.images(images, env=self.viz_name+'_reconstruction',\n",
    "                        opts=dict(title=str(self.global_iter)), nrow=10)\n",
    "        self.net_mode(train=True)\n",
    "\n",
    "    def viz_lines(self):\n",
    "        self.net_mode(train=False)\n",
    "        recon_losses = torch.stack(self.gather.data['recon_loss']).cpu()\n",
    "\n",
    "        mus = torch.stack(self.gather.data['mu']).cpu()\n",
    "        vars = torch.stack(self.gather.data['var']).cpu()\n",
    "\n",
    "        dim_wise_klds = torch.stack(self.gather.data['dim_wise_kld'])\n",
    "        mean_klds = torch.stack(self.gather.data['mean_kld'])\n",
    "        total_klds = torch.stack(self.gather.data['total_kld'])\n",
    "        klds = torch.cat([dim_wise_klds, mean_klds, total_klds], 1).cpu()\n",
    "        iters = torch.Tensor(self.gather.data['iter'])\n",
    "\n",
    "        legend = []\n",
    "        for z_j in range(self.z_dim):\n",
    "            legend.append('z_{}'.format(z_j))\n",
    "        legend.append('mean')\n",
    "        legend.append('total')\n",
    "\n",
    "        if self.win_recon is None:\n",
    "            self.win_recon = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=recon_losses,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            xlabel='iteration',\n",
    "                                            title='reconsturction loss',))\n",
    "        else:\n",
    "            self.win_recon = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=recon_losses,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        win=self.win_recon,\n",
    "                                        update='append',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            xlabel='iteration',\n",
    "                                            title='reconsturction loss',))\n",
    "\n",
    "        if self.win_kld is None:\n",
    "            self.win_kld = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=klds,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            legend=legend,\n",
    "                                            xlabel='iteration',\n",
    "                                            title='kl divergence',))\n",
    "        else:\n",
    "            self.win_kld = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=klds,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        win=self.win_kld,\n",
    "                                        update='append',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            legend=legend,\n",
    "                                            xlabel='iteration',\n",
    "                                            title='kl divergence',))\n",
    "\n",
    "        if self.win_mu is None:\n",
    "            self.win_mu = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=mus,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            legend=legend[:self.z_dim],\n",
    "                                            xlabel='iteration',\n",
    "                                            title='posterior mean',))\n",
    "        else:\n",
    "            self.win_mu = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=vars,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        win=self.win_mu,\n",
    "                                        update='append',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            legend=legend[:self.z_dim],\n",
    "                                            xlabel='iteration',\n",
    "                                            title='posterior mean',))\n",
    "\n",
    "        if self.win_var is None:\n",
    "            self.win_var = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=vars,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            legend=legend[:self.z_dim],\n",
    "                                            xlabel='iteration',\n",
    "                                            title='posterior variance',))\n",
    "        else:\n",
    "            self.win_var = self.viz.line(\n",
    "                                        X=iters,\n",
    "                                        Y=vars,\n",
    "                                        env=self.viz_name+'_lines',\n",
    "                                        win=self.win_var,\n",
    "                                        update='append',\n",
    "                                        opts=dict(\n",
    "                                            width=400,\n",
    "                                            height=400,\n",
    "                                            legend=legend[:self.z_dim],\n",
    "                                            xlabel='iteration',\n",
    "                                            title='posterior variance',))\n",
    "        self.net_mode(train=True)\n",
    "\n",
    "    def viz_traverse(self, limit=3, inter=2/3, loc=-1):\n",
    "        self.net_mode(train=False)\n",
    "        import random\n",
    "\n",
    "        decoder = self.net.decoder\n",
    "        encoder = self.net.encoder\n",
    "        interpolation = torch.arange(-limit, limit+0.1, inter)\n",
    "\n",
    "        n_dsets = len(self.data_loader.dataset)\n",
    "        rand_idx = random.randint(1, n_dsets-1)\n",
    "\n",
    "        random_img = self.data_loader.dataset.__getitem__(rand_idx)\n",
    "        random_img = Variable(cuda(random_img, self.use_cuda), volatile=True).unsqueeze(0)\n",
    "        random_img_z = encoder(random_img)[:, :self.z_dim]\n",
    "\n",
    "        random_z = Variable(cuda(torch.rand(1, self.z_dim), self.use_cuda), volatile=True)\n",
    "\n",
    "        if self.dataset == 'dsprites':\n",
    "            fixed_idx1 = 87040 # square\n",
    "            fixed_idx2 = 332800 # ellipse\n",
    "            fixed_idx3 = 578560 # heart\n",
    "\n",
    "            fixed_img1 = self.data_loader.dataset.__getitem__(fixed_idx1)\n",
    "            fixed_img1 = Variable(cuda(fixed_img1, self.use_cuda), volatile=True).unsqueeze(0)\n",
    "            fixed_img_z1 = encoder(fixed_img1)[:, :self.z_dim]\n",
    "\n",
    "            fixed_img2 = self.data_loader.dataset.__getitem__(fixed_idx2)\n",
    "            fixed_img2 = Variable(cuda(fixed_img2, self.use_cuda), volatile=True).unsqueeze(0)\n",
    "            fixed_img_z2 = encoder(fixed_img2)[:, :self.z_dim]\n",
    "\n",
    "            fixed_img3 = self.data_loader.dataset.__getitem__(fixed_idx3)\n",
    "            fixed_img3 = Variable(cuda(fixed_img3, self.use_cuda), volatile=True).unsqueeze(0)\n",
    "            fixed_img_z3 = encoder(fixed_img3)[:, :self.z_dim]\n",
    "\n",
    "            Z = {'fixed_square':fixed_img_z1, 'fixed_ellipse':fixed_img_z2,\n",
    "                 'fixed_heart':fixed_img_z3, 'random_img':random_img_z}\n",
    "        else:\n",
    "            fixed_idx = 0\n",
    "            fixed_img = self.data_loader.dataset.__getitem__(fixed_idx)\n",
    "            fixed_img = Variable(cuda(fixed_img, self.use_cuda), volatile=True).unsqueeze(0)\n",
    "            fixed_img_z = encoder(fixed_img)[:, :self.z_dim]\n",
    "\n",
    "            Z = {'fixed_img':fixed_img_z, 'random_img':random_img_z, 'random_z':random_z}\n",
    "\n",
    "        gifs = []\n",
    "        for key in Z.keys():\n",
    "            z_ori = Z[key]\n",
    "            samples = []\n",
    "            for row in range(self.z_dim):\n",
    "                if loc != -1 and row != loc:\n",
    "                    continue\n",
    "                z = z_ori.clone()\n",
    "                for val in interpolation:\n",
    "                    z[:, row] = val\n",
    "                    sample = F.sigmoid(decoder(z)).data\n",
    "                    samples.append(sample)\n",
    "                    gifs.append(sample)\n",
    "            samples = torch.cat(samples, dim=0).cpu()\n",
    "            title = '{}_latent_traversal(iter:{})'.format(key, self.global_iter)\n",
    "\n",
    "            if self.viz_on:\n",
    "                self.viz.images(samples, env=self.viz_name+'_traverse',\n",
    "                                opts=dict(title=title), nrow=len(interpolation))\n",
    "\n",
    "        if self.save_output:\n",
    "            output_dir = os.path.join(self.output_dir, str(self.global_iter))\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            gifs = torch.cat(gifs)\n",
    "            gifs = gifs.view(len(Z), self.z_dim, len(interpolation), self.nc, 64, 64).transpose(1, 2)\n",
    "            for i, key in enumerate(Z.keys()):\n",
    "                for j, val in enumerate(interpolation):\n",
    "                    save_image(tensor=gifs[i][j].cpu(),\n",
    "                               filename=os.path.join(output_dir, '{}_{}.jpg'.format(key, j)),\n",
    "                               nrow=self.z_dim, pad_value=1)\n",
    "\n",
    "                grid2gif(os.path.join(output_dir, key+'*.jpg'),\n",
    "                         os.path.join(output_dir, key+'.gif'), delay=10)\n",
    "\n",
    "        self.net_mode(train=True)\n",
    "\n",
    "    def net_mode(self, train):\n",
    "        if not isinstance(train, bool):\n",
    "            raise('Only bool type is supported. True or False')\n",
    "\n",
    "        if train:\n",
    "            self.net.train()\n",
    "        else:\n",
    "            self.net.eval()\n",
    "\n",
    "    def save_checkpoint(self, filename, silent=True):\n",
    "        model_states = {'net':self.net.state_dict(),}\n",
    "        optim_states = {'optim':self.optim.state_dict(),}\n",
    "        win_states = {'recon':self.win_recon,\n",
    "                      'kld':self.win_kld,\n",
    "                      'mu':self.win_mu,\n",
    "                      'var':self.win_var,}\n",
    "        states = {'iter':self.global_iter,\n",
    "                  'win_states':win_states,\n",
    "                  'model_states':model_states,\n",
    "                  'optim_states':optim_states}\n",
    "\n",
    "        file_path = os.path.join(self.ckpt_dir, filename)\n",
    "        with open(file_path, mode='wb+') as f:\n",
    "            torch.save(states, f)\n",
    "        if not silent:\n",
    "            print(\"=> saved checkpoint '{}' (iter {})\".format(file_path, self.global_iter))\n",
    "\n",
    "    def load_checkpoint(self, filename):\n",
    "        file_path = os.path.join(self.ckpt_dir, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            checkpoint = torch.load(file_path)\n",
    "            self.global_iter = checkpoint['iter']\n",
    "            self.win_recon = checkpoint['win_states']['recon']\n",
    "            self.win_kld = checkpoint['win_states']['kld']\n",
    "            self.win_var = checkpoint['win_states']['var']\n",
    "            self.win_mu = checkpoint['win_states']['mu']\n",
    "            self.net.load_state_dict(checkpoint['model_states']['net'])\n",
    "            self.optim.load_state_dict(checkpoint['optim_states']['optim'])\n",
    "            print(\"=> loaded checkpoint '{} (iter {})'\".format(file_path, self.global_iter))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5644cec",
   "metadata": {},
   "source": [
    "## Args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172da35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"main.py\"\"\"\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# from solver import Solver\n",
    "# from utils import str2bool\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='toy Beta-VAE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b7c49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--ckpt_name'], dest='ckpt_name', nargs=None, const=None, default='last', type=<class 'str'>, choices=None, required=False, help='load previous checkpoint. insert checkpoint filename', metavar=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser.add_argument('--train', default=True, type=str2bool, help='train or traverse')\n",
    "parser.add_argument('--seed', default=1, type=int, help='random seed')\n",
    "parser.add_argument('--cuda', default=True, type=str2bool, help='enable cuda')\n",
    "parser.add_argument('--max_iter', default=1e6, type=float, help='maximum training iteration')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='batch size')\n",
    "\n",
    "parser.add_argument('--z_dim', default=10, type=int, help='dimension of the representation z')\n",
    "parser.add_argument('--beta', default=4, type=float, help='beta parameter for KL-term in original beta-VAE')\n",
    "parser.add_argument('--objective', default='H', type=str, help='beta-vae objective proposed in Higgins et al. or Burgess et al. H/B')\n",
    "parser.add_argument('--model', default='H', type=str, help='model proposed in Higgins et al. or Burgess et al. H/B')\n",
    "parser.add_argument('--gamma', default=1000, type=float, help='gamma parameter for KL-term in understanding beta-VAE')\n",
    "parser.add_argument('--C_max', default=25, type=float, help='capacity parameter(C) of bottleneck channel')\n",
    "parser.add_argument('--C_stop_iter', default=1e5, type=float, help='when to stop increasing the capacity')\n",
    "parser.add_argument('--lr', default=1e-4, type=float, help='learning rate')\n",
    "parser.add_argument('--beta1', default=0.9, type=float, help='Adam optimizer beta1')\n",
    "parser.add_argument('--beta2', default=0.999, type=float, help='Adam optimizer beta2')\n",
    "\n",
    "parser.add_argument('--dset_dir', default='data', type=str, help='dataset directory')\n",
    "parser.add_argument('--dataset', default='CelebA', type=str, help='dataset name')\n",
    "parser.add_argument('--image_size', default=64, type=int, help='image size. now only (64,64) is supported')\n",
    "parser.add_argument('--num_workers', default=2, type=int, help='dataloader num_workers')\n",
    "\n",
    "parser.add_argument('--viz_on', default=True, type=str2bool, help='enable visdom visualization')\n",
    "parser.add_argument('--viz_name', default='main', type=str, help='visdom env name')\n",
    "parser.add_argument('--viz_port', default=8097, type=str, help='visdom port number')\n",
    "parser.add_argument('--save_output', default=True, type=str2bool, help='save traverse images and gif')\n",
    "parser.add_argument('--output_dir', default='outputs', type=str, help='output directory')\n",
    "\n",
    "parser.add_argument('--gather_step', default=1000, type=int, help='numer of iterations after which data is gathered for visdom')\n",
    "parser.add_argument('--display_step', default=10000, type=int, help='number of iterations after which loss data is printed and visdom is updated')\n",
    "parser.add_argument('--save_step', default=10000, type=int, help='number of iterations after which a checkpoint is saved')\n",
    "\n",
    "parser.add_argument('--ckpt_dir', default='checkpoints', type=str, help='checkpoint directory')\n",
    "parser.add_argument('--ckpt_name', default='last', type=str, help='load previous checkpoint. insert checkpoint filename')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9dfe0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c97fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(train=True, seed=1, cuda=True, max_iter=1000000.0, batch_size=64, z_dim=10, beta=4, objective='H', model='H', gamma=1000, C_max=25, C_stop_iter=100000.0, lr=0.0001, beta1=0.9, beta2=0.999, dset_dir='data', dataset='CelebA', image_size=64, num_workers=2, viz_on=True, viz_name='main', viz_port=8097, save_output=True, output_dir='outputs', gather_step=1000, display_step=10000, save_step=10000, ckpt_dir='checkpoints', ckpt_name='last')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29204928",
   "metadata": {},
   "source": [
    "## dsprites dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd7544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e85b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dataset: KeysView(<numpy.lib.npyio.NpzFile object at 0x0000023A8FA45930>)\n",
      "Metadata: \n",
      " {'date': 'April 2017', 'description': 'Disentanglement test Sprites dataset.Procedurally generated 2D shapes, from 6 disentangled latent factors.This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite. All possible variations of the latents are present. Ordering along dimension 1 is fixed and can be mapped back to the exact latent values that generated that image.We made sure that the pixel outputs are different. No noise added.', 'version': 1, 'latents_names': ('color', 'shape', 'scale', 'orientation', 'posX', 'posY'), 'latents_possible_values': {'orientation': array([0.        , 0.16110732, 0.32221463, 0.48332195, 0.64442926,\n",
      "       0.80553658, 0.96664389, 1.12775121, 1.28885852, 1.44996584,\n",
      "       1.61107316, 1.77218047, 1.93328779, 2.0943951 , 2.25550242,\n",
      "       2.41660973, 2.57771705, 2.73882436, 2.89993168, 3.061039  ,\n",
      "       3.22214631, 3.38325363, 3.54436094, 3.70546826, 3.86657557,\n",
      "       4.02768289, 4.1887902 , 4.34989752, 4.51100484, 4.67211215,\n",
      "       4.83321947, 4.99432678, 5.1554341 , 5.31654141, 5.47764873,\n",
      "       5.63875604, 5.79986336, 5.96097068, 6.12207799, 6.28318531]), 'posX': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
      "       0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
      "       0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
      "       0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
      "       0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
      "       0.96774194, 1.        ]), 'posY': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
      "       0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
      "       0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
      "       0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
      "       0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
      "       0.96774194, 1.        ]), 'scale': array([0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), 'shape': array([1., 2., 3.]), 'color': array([1.])}, 'latents_sizes': array([ 1,  3,  6, 40, 32, 32], dtype=int64), 'author': 'lmatthey@google.com', 'title': 'dSprites dataset'}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_zip = np.load(r'C:\\Users\\User\\Documents\\repos\\dsprites\\dsprites-dataset\\dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', encoding='latin1')\n",
    "\n",
    "print('Keys in the dataset:', dataset_zip.keys())\n",
    "imgs = dataset_zip['imgs']\n",
    "latents_values = dataset_zip['latents_values']\n",
    "latents_classes = dataset_zip['latents_classes']\n",
    "metadata = dataset_zip['metadata'][()]\n",
    "\n",
    "print('Metadata: \\n', metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e10f0722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737280, 64, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f8842",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb8a4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(args):\n",
    "#     seed = args.seed\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "#     net = Solver(args)\n",
    "\n",
    "#     if args.train:\n",
    "#         net.train()\n",
    "#     else:\n",
    "#         net.traverse()\n",
    "\n",
    "# main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690b4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --dataset dsprites --seed 2 --lr 5e-4 --beta1 0.9 --beta2 0.999 \\\n",
    "    --objective B --model B --batch_size 64 --z_dim 10 --max_iter 1.5e6 \\\n",
    "    --C_stop_iter 1e5 --C_max 20 --gamma 100 --viz_name dsprites_B_gamma100_z10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
